{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0b8e7e8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CSS 201 / 202 - CSS Bootcamp\n",
    "\n",
    "## Week 06 - Lecture 03\n",
    "\n",
    "### Umberto Mignozzetti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd506131",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## (If you want to) Configure DataHub\n",
    "\n",
    "1. Open Terminal.\n",
    "\n",
    "2. Type (substituting the **\\<XXXXyour-user-hereXXXX\\>** for your actual username).\n",
    "\n",
    "```\n",
    "mkdir mykernel\n",
    "python3 -m venv mykernel\n",
    "source mykernel/bin/activate\n",
    "\n",
    "which pip # output = /datasets/home/.../<XXXXyour-user-hereXXXX>/mykernel/bin/pip\n",
    "/home/<XXXXyour-user-hereXXXX>/mykernel/bin/python3 -m pip install --upgrade pip\n",
    "\n",
    "pip install ipython ipykernel scikit-learn seaborn statsmodels plotly\n",
    "\n",
    "which ipython # output = /datasets/home/.../<XXXXyour-user-hereXXXX>/mykernel/bin/pip/ipython\n",
    "ipython kernel install --user --name=mykernel\n",
    "deactivate\n",
    "```\n",
    "\n",
    "3. Close and open again your DataHub, now you have all up-to-date!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754b027f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55c5cf0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Loading the relevant packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting things:\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "# Loading scikit learn relevant packages (note our new friends!)\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, get_scorer_names, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3773c9f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Resampling\n",
    "\n",
    "- Involve repeatedly drawing `samples` for a `training dataset` to obtain fitting information.\n",
    "\n",
    "- `Samples`: A randomly selected fraction of the original data.\n",
    "    + Do not mistake it for a different sample from a population.\n",
    "    \n",
    "- `Training`: Training the model means to fit the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692b2555",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Resampling\n",
    "\n",
    "- This sounds weird: why not fit the model into the actual data?\n",
    "    + We would not have a measure of how well our model is doing.\n",
    "    + In the end, this matters! And matters especially for the data that we did not train the model!\n",
    "\n",
    "- In this sense, resampling is a clever trick to see how the model would do in the `real world`, without going to the real world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82158a7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Resampling\n",
    "\n",
    "- It helps us to:\n",
    "    + Evaluate the performance of the model (`Model assessment`).\n",
    "    + Select the proper flexibility for our model (`Model selection`).\n",
    "\n",
    "- Drawback: they are computationally intensive.\n",
    "    + Usually involves refitting the model again and again.\n",
    "    \n",
    "- We are going to discuss the following:\n",
    "    + `Cross-validation`: Measure the performance and select appropriate flexibility.\n",
    "    + (not this now) `Bootstrap`: Measure the accuracy of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6addc8f4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bc34ca",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Loading Chile data\n",
    "chile = pd.read_csv('https://raw.githubusercontent.com/umbertomig/POLI175public/main/data/chilesurvey.csv')\n",
    "chile_clean = chile.dropna()\n",
    "chile_clean = chile_clean[chile_clean['vote'].isin(['Y', 'N'])]\n",
    "chile_clean['vote'] = np.where(chile_clean['vote'] == 'Y', 1, 0)\n",
    "chile_clean['logincome'] = np.log(chile_clean['income'])\n",
    "chile_clean['logpop'] = np.log(chile_clean['population'])\n",
    "dummies = pd.get_dummies(chile_clean['sex'], prefix = 'sex', drop_first = True)\n",
    "chile_clean = pd.concat([chile_clean, dummies], axis=1)\n",
    "dummies = pd.get_dummies(chile_clean['region'], prefix = 'region', drop_first = True)\n",
    "chile_clean = pd.concat([chile_clean, dummies], axis=1)\n",
    "dummies = pd.get_dummies(chile_clean['education'], prefix = 'education', drop_first = True)\n",
    "chile_clean = pd.concat([chile_clean, dummies], axis=1)\n",
    "chile_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9770c9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b696a377",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Education Expenditure Dataset\n",
    "educ = pd.read_csv('https://raw.githubusercontent.com/umbertomig/POLI175public/main/data/educexp.csv')\n",
    "educ = educ.set_index('states')\n",
    "for i in educ.columns:\n",
    "    educ[i + '_log'] = np.log(educ[i])\n",
    "educ.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fb4098",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "- We talked about it yesterday.\n",
    "\n",
    "- In that context, we looked at the idea of a\n",
    "    + `training error rate` (the boring one): The error when fitting the model to data that was used to train the parameters, and\n",
    "    + `test error rate` (the cool one): The error associated with fitting the model to ***unseen*** data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266e9a46",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "### Validation Set Approach\n",
    "\n",
    "- Randomly divide the data into two sets:\n",
    "    + `Training set`: The data used to fit the model\n",
    "    + `Testing set`: The data used to test the performance of the fitted model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33edcd3c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "### Validation Set Approach\n",
    "\n",
    "- Split the sample in half training - half testing and running the estimation:\n",
    "\n",
    "![img vsa](https://github.com/umbertomig/POLI175public/blob/main/img/cv1.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8abe42",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "### Validation Set Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07616278",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## With 50% split (no urban_log)\n",
    "y = educ['education_log']\n",
    "X = educ[['income_log', 'young_log']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state = 1234)\n",
    "\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "np.sum((y_pred - y_test) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134c6037",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "### Validation Set Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e6847d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## With 50% split (with urban_log)\n",
    "y = educ['education_log']\n",
    "X = educ[['income_log', 'young_log', 'urban_log']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 1234)\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "np.sum((y_pred - y_test) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344a7dac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "### Validation Set Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750ac6ed",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Your turn: Check the MSE when removing income_log. Is it\n",
    "##  better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13823af2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "### Validation Set Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb05831",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Your turn: Check the MSE when removing 'urban_pop' \n",
    "##   with only 20% of observations in the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43173a8a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "### Leave-One-Out Cross-Validation\n",
    "\n",
    "- It does what it says: leaves one observation out and fits the model with $n-1$ cases.\n",
    "\n",
    "- Then, it predicts the results in the case left out.\n",
    "\n",
    "- **Great** for small datasets and when prediction is critical.\n",
    "\n",
    "- **Bad** in terms of computational time.\n",
    "\n",
    "$$ CV_n \\ = \\ \\dfrac{1}{n}\\sum_i MSE_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ae8ab3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "### Leave-One-Out Cross-Validation\n",
    "\n",
    "![img](https://github.com/umbertomig/POLI175public/blob/main/img/cv2.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2e40c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "### Leave-One-Out Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75f039a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## LOOCV\n",
    "## Variables: model without urban population\n",
    "y = educ['education_log']\n",
    "X = educ[['income_log','young_log']]\n",
    "\n",
    "## Leave-One-Out-CV\n",
    "cv = LeaveOneOut()\n",
    "reg = LinearRegression()\n",
    "\n",
    "## Run the CV\n",
    "scores = cross_val_score(reg, X, y,\n",
    "                         scoring = 'neg_mean_squared_error',\n",
    "                         cv = cv)\n",
    "\n",
    "## RMSE\n",
    "print(np.sqrt(np.mean(np.absolute(scores))))\n",
    "\n",
    "## MSE\n",
    "np.mean(np.absolute(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073c427a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "### Leave-One-Out Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d0d15e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## LOOCV\n",
    "## Variables: model **with** urban population\n",
    "y = educ['education_log']\n",
    "X = educ[['income_log', 'young_log', 'urban_log']]\n",
    "\n",
    "## Leave-One-Out-CV\n",
    "cv = LeaveOneOut()\n",
    "reg = LinearRegression()\n",
    "\n",
    "\n",
    "## Run the CV\n",
    "scores = cross_val_score(reg, X, y, \n",
    "                         scoring = 'neg_mean_squared_error',\n",
    "                         cv = cv)\n",
    "\n",
    "## MSE\n",
    "print(np.mean(np.absolute(scores)))\n",
    "\n",
    "## RMSE\n",
    "np.sqrt(np.mean(np.absolute(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8138d2b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "### Leave-One-Out Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eb9e5f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Your turn: compare the model with x without logs\n",
    "## Note: the target has to be the same!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cd4cbe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "### Metrics\n",
    "\n",
    "- To do the comparison, you need a metric.\n",
    "\n",
    "- `scikit learn` has many matrics available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdde1b6f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Lots of stats to compute the error:\n",
    "print(get_scorer_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dfbd28",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "### Leave-One-Out Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbf55dc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Your turn: find and use R-squared as the parameter for a\n",
    "## LOOCV. What is the difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87217f23",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "### K-Fold Cross-Validation\n",
    "\n",
    "- Leaves $k$ groups out and fits the model with the observations outside each group.\n",
    "\n",
    "- Then, it predicts the results in the cases left out.\n",
    "\n",
    "- **Great** in most cases.\n",
    "\n",
    "- **Bad** *sometimes* computationally expensive.\n",
    "\n",
    "$$ CV_k \\ = \\ \\dfrac{1}{k}\\sum_i MSE_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b281b3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "### K-Fold Cross-Validation\n",
    "\n",
    "![img](https://github.com/umbertomig/POLI175public/blob/main/img/cv3.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ea115b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "### K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253bf01f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## K-Fold CV (k = 5)\n",
    "y = educ['education_log']\n",
    "X = educ[['income_log', 'young_log']]\n",
    "\n",
    "## k-Fold CV (n_splits = k, shuffle: reshuffle data before split)\n",
    "cv = KFold(n_splits = 5, random_state = 1234, shuffle = True) \n",
    "reg = LinearRegression()\n",
    "\n",
    "\n",
    "## Run the CV\n",
    "scores = cross_val_score(reg, X, y,\n",
    "                         scoring = 'neg_mean_squared_error',\n",
    "                         cv = cv)\n",
    "\n",
    "## MSE\n",
    "print(np.mean(np.absolute(scores)))\n",
    "\n",
    "## RMSE\n",
    "np.sqrt(np.mean(np.absolute(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cbc9f7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "### K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29899042",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## K-Fold CV (k = 5)\n",
    "y = educ['education_log']\n",
    "X = educ[['income_log', 'young_log', 'urban_log']]\n",
    "\n",
    "## k-Fold CV (n_splits = k, shuffle: reshuffle data before split)\n",
    "cv = KFold(n_splits = 5, random_state = 1234, shuffle = True) \n",
    "reg = LinearRegression()\n",
    "\n",
    "\n",
    "## Run the CV\n",
    "scores = cross_val_score(reg, X, y,\n",
    "                         scoring = 'neg_mean_squared_error',\n",
    "                         cv = cv)\n",
    "\n",
    "## MSE\n",
    "print(np.mean(np.absolute(scores)))\n",
    "\n",
    "## RMSE\n",
    "np.sqrt(np.mean(np.absolute(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cac0eb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "### K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a3be41",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Your turn: Run a 10-fold CV? Any differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05794a41",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "### Bias-Variance Trade-off\n",
    "\n",
    "- k-Fold CV is more computationally efficient than LOOCV. But how about Bias-Variance Trade-offs?\n",
    "\n",
    "- Larger fractions in a two-split leads to high bias: over-estimates the error rates.\n",
    "\n",
    "- LOOCV: leaves just one, so it gives an unbiased estimate of the testing error rates: \n",
    "    + Very good for bias reduction!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f697d9d7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "### Bias-Variance Trade-off\n",
    "\n",
    "- LOOCV has high variance: almost the same observations at each run!\n",
    "    + Very bad for variance.\n",
    "    \n",
    "- k-Fold CV:\n",
    "    + Each subset is a *bit more different* than the other.\n",
    "    + Leads to less correlation between each fold.\n",
    "    + Good balance usually with $k=5$ or $k=10$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec711f60",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "### Bias-Variance Trade-off\n",
    "\n",
    "![img](https://github.com/umbertomig/POLI175public/blob/main/img/cv4.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bd57b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "### CV on Classification Problems\n",
    "\n",
    "- When we have a classification, we must change how we evaluate the error.\n",
    "\n",
    "- With classification, the LOOCV would look like this:\n",
    "\n",
    "$$ CV_n \\ = \\ \\dfrac{1}{n} \\sum_i I(y_i \\neq \\widehat{y}_i) $$\n",
    "\n",
    "- And the `accuracy` measure will be $I(y_i = \\widehat{y}_i)$, so we need to subtract 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5f488f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "### CV on Classification Problems\n",
    "\n",
    "![img](https://github.com/umbertomig/POLI175public/blob/main/img/cv5.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b4f0ed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "\n",
    "### CV on Classification Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a278eb4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## LOOCV on a Logistic Regression\n",
    "# Checking best polynomial for Age\n",
    "poly = list(range(1, 6))\n",
    "errmea = []\n",
    "y = chile_clean['vote']\n",
    "for p in poly:\n",
    "    if p == 1:\n",
    "        X = pd.DataFrame({\n",
    "            'age_1': chile_clean['age']\n",
    "        })\n",
    "    else:\n",
    "        X['age_' + str(p)] = X['age_1'] ** p\n",
    "    cv = LeaveOneOut()\n",
    "    logreg = LogisticRegression()\n",
    "    scores = cross_val_score(logreg, X, y, \n",
    "                             scoring = 'accuracy',\n",
    "                             cv = cv, n_jobs = -1)\n",
    "    print('For polynomial order {a}, the Logistic Regression Error Rate is {b}.\\n'.format(a = str(p), b = str(1-scores.mean())))\n",
    "    errmea.append(1-scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e97dd5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification\n",
    "\n",
    "### K-Nearest Neighbors Classifier\n",
    "\n",
    "- Little detour back to talk about a good algorithm for classification (also very intuitive).\n",
    "\n",
    "- Given an integer $K$, and a test observation, it says that:\n",
    "\n",
    "$$ \\mathbb{P}(Y = j| X = x_0) \\ = \\ \\dfrac{1}{K}\\sum_{i \\in N_0} I(y_i = j) $$\n",
    "\n",
    "- Meaning: classify the observation based on the class of the closest $K$ obs:\n",
    "    + The one more frequent is the winner.\n",
    "    \n",
    "- Closest: the idea of a metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cc8989",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification\n",
    "\n",
    "### K-Nearest Neighbors Classifier\n",
    "\n",
    "![img](https://github.com/umbertomig/POLI175public/blob/main/img/knn1.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f917d93",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification\n",
    "\n",
    "### K-Nearest Neighbors Classifier\n",
    "\n",
    "![img](https://github.com/umbertomig/POLI175public/blob/main/img/knn2.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6c7b1d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification\n",
    "\n",
    "### K-Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6241b4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "X = chile_clean[['age', 'statusquo']]\n",
    "y = chile_clean['vote']\n",
    "\n",
    "# Create the model\n",
    "knn = KNeighborsClassifier(n_neighbors = 10).fit(X, y)\n",
    "\n",
    "# Plotting the tree boundaries\n",
    "fig = DecisionBoundaryDisplay.from_estimator(knn, X, response_method=\"predict\",\n",
    "                                             alpha=0.5, cmap=plt.cm.coolwarm)\n",
    "\n",
    "# Plotting the data points    \n",
    "fig.ax_.scatter(x = chile_clean['age'], y = chile_clean['statusquo'], \n",
    "                c = y, alpha = 0.5,\n",
    "                cmap = plt.cm.coolwarm)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fca2b54",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification\n",
    "\n",
    "### K-Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4871d6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Now choose K! (We will learn a better method for doing this: GridSearchCV!)\n",
    "bigK = list(range(1, 100))\n",
    "errmea = []\n",
    "y = chile_clean['vote']\n",
    "X = chile_clean[['statusquo', 'logincome', 'logpop', 'age']]\n",
    "for smallk in bigK:\n",
    "    cv = KFold(n_splits = 10, random_state = 1234, shuffle = True)\n",
    "    knn = KNeighborsClassifier(n_neighbors = smallk)\n",
    "    scores = cross_val_score(knn, X, y, \n",
    "                             scoring = 'accuracy',\n",
    "                             cv = cv, n_jobs = -1)\n",
    "    errmea.append(1-scores.mean())\n",
    "print('Best K is {a}.'.format(a = str(bigK[errmea.index(min(errmea))])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fad50b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification\n",
    "\n",
    "### K-Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74ef717",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.lineplot(x = bigK, y = errmea)\n",
    "plt.title('KNN algorithm')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.scatter(bigK[errmea.index(min(errmea))], min(errmea), marker='X', color = 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aef0b3c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification\n",
    "\n",
    "**Check-in:** Study the best method for predicting default in credit card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b5a9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "default = pd.read_csv('https://raw.githubusercontent.com/umbertomig/POLI175public/main/data/default.csv')\n",
    "default.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34284d68",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Model Selection and Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fa7783",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "- We usually have a large set of predictors that could be used.\n",
    "    + Which predictors to pick becomes a task.\n",
    "\n",
    "- If we are trying to interpret things and learn from the data, then which predictors are correlated with the outcome is informative:\n",
    "    + Again, picking predictors becomes a task.\n",
    "    \n",
    "- We will learn how to do that systematically.\n",
    "    - We are going to consider techniques to select a subset of predictors based on a performance metric.\n",
    "    - Later we will see other techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a895fc4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "### Subset Selection\n",
    "\n",
    "#### Best Subset Selection\n",
    "\n",
    "**Algorithm:**\n",
    "\n",
    "1. Let $M_0$ denote the null model, which contains no predictors. This model predicts the sample mean for each observation.\n",
    "\n",
    "2. For $k = \\{1, 2, \\cdots, p\\}$:\n",
    "    1. Fit all $p \\choose k$ models with exactly $k$ predictors.\n",
    "    2. Pick the *best* among these models and call it your $M_k$\n",
    "\n",
    "3. Select a single best model from among $M_0, \\cdots, M_p$ using cross-validated prediction error, $C_p$, AIC, BIC, or adjusted $R^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85f7ad3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "### Subset Selection\n",
    "\n",
    "#### Best Subset Selection\n",
    "\n",
    "![img ms1](https://github.com/umbertomig/POLI175public/blob/main/img/ms1.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700d9c80",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "### Subset Selection\n",
    "\n",
    "#### Best Subset Selection\n",
    "\n",
    "Notes:\n",
    "\n",
    "1. You can do this with Logistic Regression: change RSS with [*deviance*](https://en.wikipedia.org/wiki/Deviance_(statistics)).\n",
    "    + In this case, our friend $- 2\\ln({\\hat {L}})$ does very well!\n",
    "\n",
    "2. Best Selection is excellent but fits around $2^p$ models.\n",
    "    + $p = 10$ means around 1000 estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ae65cf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "### Subset Selection\n",
    "\n",
    "#### Stepwise Selection: Forward Selection\n",
    "\n",
    "**Algorithm**:\n",
    "\n",
    "1. Let $M_0$ denote the null model, which contains no predictors.\n",
    "\n",
    "2. For $k = \\{0, 1, 2, \\cdots, p-1\\}$:\n",
    "    1. Consider all $p - k$ models that augments $M_k$ by one predictor.\n",
    "    2. Pick the *best* among these $p-k$ models, and call it your $M_{k+1}$.\n",
    "\n",
    "3. Select a single best model from among $M_0, \\cdots, M_p$ using cross-validated prediction error, $C_p$, AIC, BIC, or adjusted $R^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0310fbb9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "### Subset Selection\n",
    "\n",
    "#### Stepwise Selection: Forward Selection\n",
    "\n",
    "- Much more efficient:\n",
    "    + It fits a total of $1 + \\dfrac{p(p+1)}{2}$ models.\n",
    "    + If $p = 20$, the Best Selection would fit 1,048,576\n",
    "    + If $p = 20$, the Forward Step Selection would fit 211 models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9800b97a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "### Subset Selection\n",
    "\n",
    "#### Stepwise Selection: Forward Selection\n",
    "\n",
    "- The catch: It is not guaranteed that it is going to find the *best subset* model.\n",
    "\n",
    "- Example: Let $p = 3$.\n",
    "    + Suppose that the best model involves $v2$ and $v3$.\n",
    "    + But suppose that within the models with only one variable, $v1$ would do better.\n",
    "    + Then, Forward Step Selection would never pick this model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137afa72",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "### Subset Selection\n",
    "\n",
    "#### Stepwise Selection: Forward Selection\n",
    "\n",
    "![img ms2](https://github.com/umbertomig/POLI175public/blob/main/img/ms2.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18094e36",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "### Subset Selection\n",
    "\n",
    "#### Stepwise Selection: Backward Selection\n",
    "\n",
    "**Algorithm**:\n",
    "\n",
    "1. Let $M_p$ denote the *full* model, which contains all $p$ predictors.\n",
    "\n",
    "2. For $k = \\{p, p-1, p-2, \\cdots, 1\\}$:\n",
    "    1. Consider all $k$ models that contail all but one predictor in $M_k$, for a total of $k-1$ predictors.\n",
    "    2. Pick the *best* among these $k$ models, and call it your $M_{k-1}$.\n",
    "\n",
    "3. Select a single best model from among $M_0, \\cdots, M_p$ using cross-validated prediction error, $C_p$, AIC, BIC, or adjusted $R^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946591fa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "### Subset Selection\n",
    "\n",
    "#### Stepwise Selection: Backward Selection\n",
    "\n",
    "- Computational Efficiency:\n",
    "    + It fits a total of $1 + \\dfrac{p(p+1)}{2}$ models.\n",
    "    + Same efficiency as the Forward Selection.\n",
    "\n",
    "- Catch:\n",
    "    + Same catch as the Forward Selection: It does not guarantee the pick of the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab716aa3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "### Subset Selection\n",
    "\n",
    "#### Stepwise Selection: Hybrid Approaches\n",
    "\n",
    "- Combinations of *Forward* and *Backwards* that intend to mimic the *Best Selection*.\n",
    "\n",
    "- Many available.\n",
    "\n",
    "- But the trade-offs are clear: \n",
    "    + Computational efficiency\n",
    "    + Likelihood of picking the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4162de94",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "### Subset Selection\n",
    "\n",
    "#### What is Best?\n",
    "\n",
    "- For each of the $M_k$ models, this is it:\n",
    "    + RSS: Residual Sum of Squares: We want it to be the lowest possible.\n",
    "    + $R^2$: We want it to be the highest possible.\n",
    "    + And for Logistic or other GLM Regressions, *deviance*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6515e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "### Subset Selection\n",
    "\n",
    "#### What is Best?\n",
    "\n",
    "- Catches: \n",
    "    1. RSS and $R^2$ always improve with more variables.\n",
    "    2. We want to look at the *testing set goodness-of-fit*, not the *training sets goodness-of-fit*!\n",
    "\n",
    "- And that is why RSS and $R^2$ are not used in Step 3:\n",
    "    - We need something that eventually gets worse the more variables we throw in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9c8d08",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "### Subset Selection\n",
    "\n",
    "#### What is Best?\n",
    "\n",
    "**Important:**\n",
    "\n",
    "- Training Set MSE generally underestimates the testing set MSE.\n",
    "\n",
    "$$ \\text{MSE} \\ = \\ \\dfrac{RSS}{n} $$\n",
    "\n",
    "- But before, we could not split data into *training* and *testing*. \n",
    "    + This is a more recent feature, thanks to our increased computational power.\n",
    "\n",
    "- Here are a few stats that we can fit in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405961b4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "### Subset Selection\n",
    "\n",
    "#### What is Best?\n",
    "\n",
    "- [$C_P$](https://en.wikipedia.org/wiki/Mallows%27s_Cp) in a model containing:\n",
    "    - $d$ predictors.\n",
    "    - $n$ observations.\n",
    "    - $\\widehat{\\sigma}^2$ the variance of the error in the full model with all predictors.\n",
    "\n",
    "$$ C_p \\ = \\ \\dfrac{1}{n}(RSS + 2\\times d \\times \\widehat{\\sigma}^2) $$\n",
    "\n",
    "- The smaller, the better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e341490e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "### Subset Selection\n",
    "\n",
    "#### What is Best?\n",
    "\n",
    "- [AIC](https://en.wikipedia.org/wiki/Akaike_information_criterion) or $C_p$: AIC is a goodness-of-fit parameters that goes lower when you are improving the model\n",
    "    + But for every variable you add, it penalizes it.\n",
    "    + If by adding more variables, it goes up, then your model is getting more complex without adding much.\n",
    "    \n",
    "$$ \\text{AIC} \\ = \\ 2d - 2\\log({\\hat {L}}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0aa375",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "### Subset Selection\n",
    "\n",
    "#### What is Best?\n",
    "\n",
    "- The maximum likelihood and least squares are the same for models with Gaussian errors.\n",
    "\n",
    "$$ \\text{AIC} \\ = \\ \\dfrac{1}{n} (RSS + 2\\times d \\times \\widehat{\\sigma}^2) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96828005",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "### Subset Selection\n",
    "\n",
    "#### What is Best?\n",
    "\n",
    "- [BIC](https://en.wikipedia.org/wiki/Bayesian_information_criterion) is another goodness-of-fit, but this one penalizes the addition of variables at a higher rate.\n",
    "\n",
    "$$ \\text{BIC} = k\\log(n) - 2\\log({\\widehat {L}}) $$\n",
    "\n",
    "- Note the difference from the AIC: instead of multiplying by 2, it is multiplying by $\\ln(n)$!\n",
    "\n",
    "- Again, lower values are better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cac0e50",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "### Subset Selection\n",
    "\n",
    "#### What is Best?\n",
    "\n",
    "- Or if you want the one with the least square errors:\n",
    "\n",
    "$$ \\text{AIC} \\ = \\ \\dfrac{1}{n} (RSS + \\log(n) \\times d \\times \\widehat{\\sigma}^2)  $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a7dace",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "### Subset Selection\n",
    "\n",
    "#### What is Best?\n",
    "\n",
    "- [Adjusted $R^2$](https://en.wikipedia.org/wiki/Bayesian_information_criterion): It is a change in the $R^2$ to penalize the addition of regressors.\n",
    "\n",
    "$$ \\overline{R}^{2} = 1-(1-R^{2})\\dfrac{n-1}{n-d} \\ = \\ 1 - \\dfrac{\\frac{RSS}{n - d - 1}}{\\frac{TSS}{n - 1}}$$\n",
    "\n",
    "- $R^2$ always increase but the $\\overline{R}^2$ may increase or decrese.\n",
    "\n",
    "- **Not like the others:** This one, the higher, the better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228e5bb2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "### Subset Selection\n",
    "\n",
    "#### What is Best?\n",
    "\n",
    "![img ms3](https://github.com/umbertomig/POLI175public/blob/main/img/ms3.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2291cc9c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "### Subset Selection\n",
    "\n",
    "#### What is Best?\n",
    "\n",
    "- $C_P$, AIC, and BIC all have a solid theoretical justification.\n",
    "    + Many of them have something we call Large Sample Properties.\n",
    "    + Check their Wikipedia of them. They converge to nice, important values.\n",
    "\n",
    "- $\\overline{R}^{2}$ does not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceca471",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "### Subset Selection\n",
    "\n",
    "#### What is best? Validation and Cross-Validation\n",
    "\n",
    "- The main advantage is obvious: You look at testing errors!\n",
    "\n",
    "- The other main advantage is regarding estimating parameters:\n",
    "    + $C_P$, AIC, and BIC all have a strong theoretical justification, which is reassuring.\n",
    "    + But sometimes, one does not know the theory behind an estimate to compute statistics or even standard errors.\n",
    "    + E.g., which $\\widehat{\\sigma}^2$ should we pick?\n",
    "    + Validation and Cross-Validation do great in these cases!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64d1ae6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "### Subset Selection\n",
    "\n",
    "#### What is best? Validation and Cross-Validation\n",
    "\n",
    "![img ms4](https://github.com/umbertomig/POLI175public/blob/main/img/ms4.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338dda0e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "### Subset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4704653f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Loading Chile data\n",
    "chile = pd.read_csv('https://raw.githubusercontent.com/umbertomig/POLI175public/main/data/chilesurvey.csv')\n",
    "chile_clean = chile.dropna()\n",
    "chile_clean = chile_clean[chile_clean['vote'].isin(['Y', 'N'])]\n",
    "chile_clean['vote'] = np.where(chile_clean['vote'] == 'Y', 1, 0)\n",
    "chile_clean['logincome'] = np.log(chile_clean['income'])\n",
    "chile_clean['logpop'] = np.log(chile_clean['population'])\n",
    "dummies = pd.get_dummies(chile_clean['sex'], prefix = 'sex', drop_first = True)\n",
    "chile_clean = pd.concat([chile_clean, dummies], axis=1)\n",
    "dummies = pd.get_dummies(chile_clean['region'], prefix = 'region', drop_first = True)\n",
    "chile_clean = pd.concat([chile_clean, dummies], axis=1)\n",
    "dummies = pd.get_dummies(chile_clean['education'], prefix = 'education', drop_first = True)\n",
    "chile_clean = pd.concat([chile_clean, dummies], axis=1)\n",
    "chile_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849f461f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "### Subset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4e0f45",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Education Expenditure Dataset\n",
    "educ = pd.read_csv('https://raw.githubusercontent.com/umbertomig/POLI175public/main/data/educexp.csv')\n",
    "educ = educ.set_index('states')\n",
    "for i in educ.columns:\n",
    "    educ[i + '_log'] = np.log(educ[i])\n",
    "educ.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2afb6e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stepwise Subset Selection: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337e1c87",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Let us predict the education expenditure using\n",
    "## raws, squares, and cubic powers of the predictors\n",
    "raws = ['income', 'young', 'urban']\n",
    "y = educ['education']\n",
    "X = educ.reset_index()[raws]\n",
    "for power in range(2, 4):\n",
    "    for var in raws:\n",
    "        X[var + '_' + str(power)] = X[[var]] ** power\n",
    "\n",
    "# Found on stackoverflow\n",
    "def powerSet(s):\n",
    "    sets = [[]]\n",
    "    for i in s:\n",
    "        newsets = []\n",
    "        for k in sets:\n",
    "            newsets.append(k+[i])\n",
    "        sets += newsets\n",
    "    return sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce0455e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stepwise Subset Selection: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672df954",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## My best subset selection code\n",
    "def best_subset_selection(est, X, y, cvn = 5):\n",
    "    modsAll = powerSet(X.columns)\n",
    "    mods = {}\n",
    "    for i in modsAll:\n",
    "        if i == []:\n",
    "            mods[0] = {'model': 'Null',\n",
    "                       'RSS': np.sum((y - np.mean(y)) ** 2)}\n",
    "        else:\n",
    "            rss = np.sum((y - est.fit(X[i], y).predict(X[i])) ** 2)\n",
    "            if len(i) not in mods:\n",
    "                mods[len(i)] = {'model': i, 'RSS': rss}\n",
    "            else:\n",
    "                if mods[len(i)]['RSS'] > rss:\n",
    "                    mods[len(i)] = {'model': i, 'RSS': rss}\n",
    "    bestmod = mods.pop(0)\n",
    "    bestmod.pop('RSS')\n",
    "    bestmod['Rsquared'] = 0\n",
    "    for i in mods.values():\n",
    "        score = cross_val_score(est, X[i['model']], y, cv = cvn, scoring = 'r2').mean()\n",
    "        if bestmod['Rsquared'] < score:\n",
    "            bestmod['model'] = i['model']\n",
    "            bestmod['Rsquared'] = score\n",
    "    return(bestmod)\n",
    "\n",
    "print(best_subset_selection(LinearRegression(), X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70c8018",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Forward Subset Selection: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945da493",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## My forward subset selection\n",
    "def forward_subset_selection(est, X, y, cvn = 5):\n",
    "    variables = list(X.columns)\n",
    "    mods = {}\n",
    "    mods[0] = {'model': [], 'RSS': np.sum((y - np.mean(y)) ** 2)}\n",
    "    for i in range(1, len(variables) + 1):\n",
    "        mods[i] = {'model': mods[i-1]['model'], 'RSS': mods[i-1]['RSS']}\n",
    "        for j in [item for item in variables if item not in mods[i-1]['model']]:\n",
    "            varsaux = mods[i-1]['model'] + [j]\n",
    "            rss = np.sum((y - est.fit(X[varsaux], y).predict(X[varsaux])) ** 2)\n",
    "            if mods[i]['RSS'] > rss:\n",
    "                mods[i]['model'] = varsaux\n",
    "                mods[i]['RSS'] = rss\n",
    "    bestmod = mods.pop(0)\n",
    "    bestmod.pop('RSS')\n",
    "    bestmod['Rsquared'] = 0\n",
    "    for i in mods.values():\n",
    "        score = cross_val_score(est, X[i['model']], y, cv = cvn, scoring = 'r2').mean()\n",
    "        if bestmod['Rsquared'] < score:\n",
    "            bestmod['model'] = i['model']\n",
    "            bestmod['Rsquared'] = score\n",
    "    return(bestmod)\n",
    "\n",
    "print(forward_subset_selection(LinearRegression(), X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce353843",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Forward Subset Selection: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a970d4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Forward Stepwise Selection in Scikit Learn:\n",
    "reg = LinearRegression()\n",
    "sfs = SequentialFeatureSelector(reg, n_features_to_select='auto', direction = 'forward')\n",
    "sfs.fit(X, y)\n",
    "X.columns[sfs.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c15e749",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Backward Subset Selection: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afac680",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Backward Stepwise Selection in Scikit Learn:\n",
    "reg = LinearRegression()\n",
    "sfs = SequentialFeatureSelector(reg, n_features_to_select='auto', direction = 'backward')\n",
    "sfs.fit(X, y)\n",
    "X.columns[sfs.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9498bc3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Backward Subset Selection: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f022ecfd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Backward Stepwise Selection in Scikit Learn. Limiting to tops three features.\n",
    "reg = LinearRegression()\n",
    "sfs = SequentialFeatureSelector(reg, n_features_to_select=3, direction = 'backward')\n",
    "sfs.fit(X, y)\n",
    "X.columns[sfs.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b72f2f6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Model Selection and Regularization\n",
    "\n",
    "- Now we are going to focus on two of the most used methods for model selection:\n",
    "    + **Ridge**\n",
    "    + **Lasso**\n",
    "\n",
    "- These methods are different from the subset selection in special ways:\n",
    "    + They are meant to \"*shrink*\" the coefficients toward zero!\n",
    "\n",
    "- It may be counter-intuitive, but these methods are great tools to reduce the variance of the estimates (recall the bias-variance trade-offs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cad5fa0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ridge Regression\n",
    "\n",
    "- Instead of minimizing the RSS, one minimizes:\n",
    "\n",
    "$$ RSS + \\underbrace{\\alpha \\sum_{j=1}^p\\beta_j^2}_{\\text{shrinkage penalty}} $$\n",
    "\n",
    "- The $\\alpha \\geq 0$ parameters is called *tuning parameter*. \n",
    "\n",
    "- Selecting a good $\\alpha$ is crucial for a good set of estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3214eb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Ridge Regression (badly done)\n",
    "ridge = Ridge(alpha = 1).fit(X, y)\n",
    "print('The R-squared for this regression is: ' + str(ridge.score(X, y)))\n",
    "plt.bar(X.columns, ridge.coef_)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd2cbad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ridge Regression\n",
    "\n",
    "- $\\alpha = 0$ is the same as the least square regression.\n",
    "\n",
    "- As $\\alpha$ grows, the shrinkage penalty increases, and the ridge coefficients approach zero.\n",
    "\n",
    "**Caveat 1**: The scale of the variable influences the results.\n",
    "\n",
    "- In a OLS (standard least square regression), when you multiply $x_j$ by $c \\neq 0$, you divide $\\beta_j$ by $\\dfrac{1}{c}$.\n",
    "\n",
    "- Example: If you measure GDP in USD vs Millions of USD changes the ridge regression coefficient significantly.\n",
    "\n",
    "**Suggestion**: Standardize the variables before running the regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd71f8d0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ridge Regression\n",
    "\n",
    "### Standardization\n",
    "\n",
    "- Let a variable $x_j$. Then, the standardized variable $z_j$ is obtained by:\n",
    "    1. Subtracting the mean of the variable $x_j$ ($\\overline{x}_j$) and then,\n",
    "    2. Dividing the result by the standard deviation ($\\sigma_{x_j}$) of the variable $x_j$.\n",
    "\n",
    "$$ z_j \\ = \\ \\dfrac{x_j - \\overline{x}_j}{\\sigma_{x_j}} $$\n",
    "\n",
    "- The resulting variable $z_j$ has mean zero, variance one, and has no unit!\n",
    "\n",
    "- Variations of one unit are called *deviations*: In a regression with a standardized variable, we say that $\\beta_j$ would represent a variation on average $y$ when we increase $z_j$ by one standard-deviation.\n",
    "\n",
    "- This is a great practice for prediction, but in general, be mindful about the unit of your data.\n",
    "\n",
    "- **Again:** In a standard least square regression, when you multiply $x_j$ by $c \\neq 0$, you divide $\\beta_j$ by $\\dfrac{1}{c}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2621d5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Standardizing the X variables\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# First observation:\n",
    "print(list(X.iloc[0]))\n",
    "print(list(X_scaled[0])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc4f1ad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bb6144",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Ridge Regression (greatly done)\n",
    "ridge = Ridge(alpha = 1).fit(X_scaled, y)\n",
    "print('The R-squared for this regression is: ' + str(ridge.score(X_scaled, y)))\n",
    "plt.bar(X.columns, ridge.coef_)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef18f434",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ridge Regression\n",
    "\n",
    "- **Caveat 2**: The ridge regression produces a different set of parameter for each $\\alpha$.\n",
    "    + $\\widehat{\\beta}_{\\alpha}^{R}$\n",
    "\n",
    "- Also note that the intercept ($\\beta_0$) is not considered.\n",
    "    + We do not want to shrink the mean of $y_i$ when $x_{ij} = 0$ for all $j$.\n",
    "    + And if we standardize the variables, then the intercept will be $\\widehat{\\beta}_0 = \\overline{y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beffbf90",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ridge Regression (book calls the reg parameter $\\lambda$)\n",
    "\n",
    "![img](https://github.com/umbertomig/POLI175public/blob/main/img/ridge1.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7ae0eb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a1e6f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Example by Kornel Kielczewski in the sklearn documentation, adapted by me.\n",
    "ridge = Ridge()\n",
    "coefs = list()\n",
    "errors = list()\n",
    "alphas = np.logspace(-6, 6, 200)\n",
    "\n",
    "for a in alphas:\n",
    "    ridge.set_params(alpha = a).fit(X_scaled, y)\n",
    "    coefs.append(ridge.coef_)\n",
    "    errors.append(np.mean((ridge.predict(X_scaled) - y) ** 2))\n",
    "\n",
    "coefs = pd.DataFrame(coefs, columns = X.columns, index = alphas)\n",
    "print(errors[0:5])\n",
    "coefs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44cf5a3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c5d6ca",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Coefficients as a function of the regularization paramenter alpha\n",
    "g = sns.lineplot(data = coefs)\n",
    "g.set(xscale='log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf7ecb8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ee0054",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Mean Squared Error as a function of the regularization paramenter alpha\n",
    "g = sns.lineplot(x = alphas, y = errors)\n",
    "g.set(xscale='log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bfce71",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ridge Regression\n",
    "\n",
    "- Advantage: the *non-obvious* advantage is that as $\\alpha$ increses, the flexibility of the model decreases.\n",
    "\n",
    "- This decreases variance (but increase bias).\n",
    "\n",
    "- This may be \"optimized\": You may find the optimal bias-variance trade-off by manipulating $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7158f624",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ridge Regression\n",
    "\n",
    "- Specially important when $p$ is close to $n$ (number of predictors is close to the number of cases).\n",
    "    + This is called *high dimensional data*.\n",
    "\n",
    "- If $p > n$, then ridge does very well. This case would have a very high variance.\n",
    "\n",
    "- And it is *way* better than *best subset selection*: you fit just one model:\n",
    "    + In practice, as many as the different $\\alpha$s.\n",
    "    + There are algorithms to solve efficiently for all $\\alpha$s, which means that it may be more efficient than best, forward, and backward stepwise selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6c8fca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ridge Regression (the book calls the regularization parameter $\\lambda$) \n",
    "\n",
    "![img](https://github.com/umbertomig/POLI175public/blob/main/img/ridge2.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cac4223",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Cross-Validation\n",
    "\n",
    "## Cross-Validation\n",
    "\n",
    "- To select the tuning parameters you can use cross-validation.\n",
    "\n",
    "- The idea is to search through a grid of tuning parameter candidates, selecting the one that does best in the cross-validation.\n",
    "\n",
    "- It is indeed a very straight-forward idea, if you think about it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da1594e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation (the book calls the regularization parameter $\\lambda$) \n",
    "\n",
    "![img](https://github.com/umbertomig/POLI175public/blob/main/img/cvridge.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9db3f1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation (the book calls the regularization parameter $\\lambda$) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e196cba6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Ridge with Cross-Validation\n",
    "ridge = Ridge()\n",
    "coefs = list()\n",
    "errors = list()\n",
    "CVerrors = list()\n",
    "alphas = np.logspace(-6, 6, 200)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.25, random_state = 12345)\n",
    "\n",
    "for a in alphas:\n",
    "    ridge.set_params(alpha = a).fit(X_train, y_train)\n",
    "    CVerrors.append(np.mean((ridge.predict(X_test) - y_test) ** 2))\n",
    "    errors.append(np.mean((ridge.predict(X_train) - y_train) ** 2))\n",
    "\n",
    "print('The alpha that minimizes the ridge testing set MSE is: ' + str(alphas[CVerrors.index(min(CVerrors))]))\n",
    "    \n",
    "mses = pd.DataFrame({\n",
    "    'trainMSE': errors,\n",
    "    'testMSE': CVerrors}, index = alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04992e0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross-Validation (the book calls the regularization parameter $\\lambda$) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4331dd24",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Cross Validation Ridge MSE as a function of the regularization parameter alpha\n",
    "g = sns.lineplot(data = mses)\n",
    "g.set(xscale='log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88da1fc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4569a8a7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lasso Regression\n",
    "\n",
    "- Ridge regression has one disadvantage: it most of the time includes $p$ predictors.\n",
    "\n",
    "- The shrinkage never sets coefficients to be exactly zero (that is, be removed from the prediction).\n",
    "\n",
    "- This could potentially make subset selection better than ridge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925dd8fa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lasso Regression\n",
    "\n",
    "- But one alternative, using the same principles as the ridge regression is the **lasso** regression.\n",
    "\n",
    "- In the lasso regression, the objective function becomes:\n",
    "\n",
    "$$ RSS + \\alpha \\sum_{j=1}^p|\\beta_j| $$\n",
    "\n",
    "- Does the same as ridge: the larger the $\\alpha$, the more the *shrinkage*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e0be89",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lasso Regression\n",
    "\n",
    "- Unlike ridge, for some values of $\\alpha$, **lasso** actually force coefficients to be exactly equal to zero.\n",
    "\n",
    "- Thus, **lasso** performs variable selection, much like the subset selection models we have seen.\n",
    "\n",
    "- **Side-effect**: Makes models easier to interpret!\n",
    "    + Yields *sparse* models: models that only involve a subset of the variables.\n",
    "    \n",
    "- Like ridge, selecting a good $\\alpha$ is critical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed7a99e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Lasso Regression (badly done)\n",
    "lasso = Lasso(alpha = 1).fit(X, y)\n",
    "print('The R-squared for this regression is: ' + str(lasso.score(X, y)))\n",
    "plt.bar(X.columns, lasso.coef_)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84848a07",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Lasso Regression (greatly done)\n",
    "lasso = Lasso(alpha = 1).fit(X_scaled, y)\n",
    "print('The R-squared for this regression is: ' + str(lasso.score(X_scaled, y)))\n",
    "plt.bar(X.columns, lasso.coef_)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "print(lasso.intercept_)\n",
    "print(np.mean(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10333971",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lasso (the book calls the regularization parameter $\\lambda$) \n",
    "\n",
    "![img](https://github.com/umbertomig/POLI175public/blob/main/img/lasso1.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf5a069",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Example by Kornel Kielczewski in the sklearn Ridge documentation, adapted by me.\n",
    "lasso = Lasso(max_iter = 20000000)\n",
    "coefs = list()\n",
    "errors = list()\n",
    "alphas = np.logspace(-6, 6, 200)\n",
    "\n",
    "for a in alphas:\n",
    "    lasso.set_params(alpha = a).fit(X_scaled, y)\n",
    "    coefs.append(lasso.coef_)\n",
    "    errors.append(np.mean((lasso.predict(X_scaled) - y) ** 2))\n",
    "\n",
    "coefs = pd.DataFrame(coefs, columns = X.columns, index = alphas)\n",
    "print(errors[0:5])\n",
    "coefs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d903124",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Lasso coefficients as a function of the regularization paramenter alpha\n",
    "g = sns.lineplot(data = coefs)\n",
    "g.set(xscale='log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0084cdf8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Lasso Mean Squared Error as a function of the regularization paramenter alpha\n",
    "g = sns.lineplot(x = alphas, y = errors)\n",
    "g.set(xscale='log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48efbc6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lasso x Ridge Regression (the book calls the regularization parameter $\\lambda$) \n",
    "\n",
    "- Selection property of lasso: \n",
    "    + Lasso and ridge are equivalent to a constraint on the shape of the acceptable parameter space.\n",
    "    + But the \"diamond shape\" of lasso makes it shrinks some coefficients towards zero.\n",
    "\n",
    "![img](https://github.com/umbertomig/POLI175public/blob/main/img/lassovsridge3.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000174f5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lasso x Ridge Regression (the book calls the regularization parameter $\\lambda$) \n",
    "\n",
    "- Lasso performs similarly to ridge in most cases. In these cases, I'd say that lasso is better:\n",
    "    + Reduces the complexity in the model.\n",
    "\n",
    "![img](https://github.com/umbertomig/POLI175public/blob/main/img/lassovsridge1.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3276c1c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lasso x Ridge Regression (the book calls the regularization parameter $\\lambda$) \n",
    "\n",
    "- But when all coefficients are different from zero, then ridge is better.\n",
    "\n",
    "![img](https://github.com/umbertomig/POLI175public/blob/main/img/lassovsridge2.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6bd627",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lasso x Ridge Regression\n",
    "\n",
    "- To summarize, none is better in all situations.\n",
    "\n",
    "- You may need to search which model is better.\n",
    "\n",
    "- Moreover, finding $\\alpha$ is also a big deal. Cross-validation can help us with that!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f968db",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Cross-Validation\n",
    "\n",
    "## Cross-Validation\n",
    "\n",
    "- To select the tuning parameters you can use cross-validation.\n",
    "\n",
    "- The idea is to search through a grid of tuning parameter candidates, selecting the one that does best in the cross-validation.\n",
    "\n",
    "- It is indeed a very straight-forward idea, if you think about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d71300",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lasso with Cross-Validation\n",
    "lasso = Lasso(max_iter = 20000000)\n",
    "coefs = list()\n",
    "errors = list()\n",
    "CVerrors = list()\n",
    "alphas = np.logspace(-6, 6, 50)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2, random_state = 12345)\n",
    "\n",
    "for a in alphas:\n",
    "    lasso.set_params(alpha = a).fit(X_train, y_train)\n",
    "    CVerrors.append(np.mean((lasso.predict(X_test) - y_test) ** 2))\n",
    "    errors.append(np.mean((lasso.predict(X_train) - y_train) ** 2))\n",
    "\n",
    "print('The alpha that minimizes the Lasso Cross-Validation MSE is: ' + str(alphas[CVerrors.index(min(CVerrors))]))\n",
    "    \n",
    "mses = pd.DataFrame({\n",
    "    'trainMSE': errors,\n",
    "    'testMSE': CVerrors}, index = alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991743e6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Cross Validation Lasso MSE as a function of the regularization parameter alpha\n",
    "g = sns.lineplot(data = mses)\n",
    "g.set(xscale='log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256a1fba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Beyond Linearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff5a223",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Beyond Linearity\n",
    "\n",
    "- So far, we have focused on linear models.\n",
    "\n",
    "- Most of the time, linear approximations are excellent:\n",
    "    + Easy to interpret\n",
    "    + Easy to run\n",
    "\n",
    "- And all the GLM flavors afford lots of flexibility regarding how we deal with data.\n",
    "\n",
    "- We will now relax the linearity assumption but keep it as simple as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797cddd0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Polynomial Regression\n",
    "\n",
    "- Expands the default model ($y_i = \\beta_0 + \\beta_1x_i + \\varepsilon_i$) to consider a polynomial $d$:\n",
    "\n",
    "$$ y_i = \\beta_0 + \\beta_1x_i + \\beta_2x_i^2 +\\cdots + \\beta_dx_i^d + \\varepsilon_i $$\n",
    "                     \n",
    "- Lots of flexibility here, but we seldom use $d>4$ because then it gets *excessively* flexible.\n",
    "\n",
    "- Prediction very straightforward:\n",
    "\n",
    "$$ \\hat{f}(x_0) = \\hat{\\beta}_0 + \\hat{\\beta}_1x_0 + \\hat{\\beta}_2x_0^2 +\\cdots + \\hat{\\beta}_dx_0^d $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a35d11",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Polynomial Regression\n",
    "\n",
    "![img](https://github.com/umbertomig/POLI175public/blob/main/img/polyreg1.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea01a5a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5410a180",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Create the polynomials (with interaction terms!)\n",
    "poly = PolynomialFeatures(degree = 4)\n",
    "X = educ.reset_index()['income'].to_frame()\n",
    "X = poly.fit_transform(X)\n",
    "print(list(poly.get_feature_names_out(['income'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa80f0e0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b538376e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Fit a linear regression\n",
    "reg = LinearRegression().fit(X, y)\n",
    "print('The MSE for a quartic polynomial is: ' + str(np.mean((reg.predict(X) - y) ** 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790a73e6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ce0748",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# For the fully-specified model (lots of interactions...)\n",
    "poly = PolynomialFeatures(degree = 4)\n",
    "X = educ.reset_index()[['income', 'urban', 'young']]\n",
    "X = poly.fit_transform(X)\n",
    "print(list(poly.get_feature_names_out(['income', 'urban', 'young'])))\n",
    "## Fit a linear regression\n",
    "reg = LinearRegression().fit(X, y)\n",
    "print('\\n\\nThe MSE for a quartic polynomial on income, urban, and \\nyoung + interactions, is: ' + str(np.mean((reg.predict(X) - y) ** 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d02bd8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8859ea",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## With cross-validation now\n",
    "\n",
    "# Only income\n",
    "X = educ.reset_index()['income'].to_frame()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 12345)\n",
    "X_train = poly.fit_transform(X_train)\n",
    "X_test = poly.fit_transform(X_test)\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "print('The CV-MSE for a quartic polynomial on income is: ' + str(np.mean((reg.predict(X_test) - y_test) ** 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ba06b2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f69fc0a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## With cross-validation now\n",
    "\n",
    "# For the fully-specified model (lots of interactions...)\n",
    "X = educ.reset_index()[['income', 'urban', 'young']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 12345)\n",
    "X_train = poly.fit_transform(X_train)\n",
    "X_test = poly.fit_transform(X_test)\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "print('The CV-MSE for a quartic polynomial on income, urban, and \\nyoung + interactions, is: ' + str(np.mean((reg.predict(X_test) - y_test) ** 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c29e2f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Piecewise-constant Regression\n",
    "\n",
    "- Here, we would be breaks in the predictor, making it an ordered categorical variable instead of a continuous variable.\n",
    "\n",
    "- Let a variable $X$, the indicator function $I(.)$, and a set of cutpoints $\\{c_1, c_2, \\cdots, c_k\\}$. The stepped variable $X$, $C_j(X)$, becomes:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "C_{0}(X) &= I(X < c_1) \\\\\n",
    "C_{1}(X) &= I(c_1 \\leq X < c_2) \\\\\n",
    "C_{2}(X) &= I(c_2 \\leq X < c_3) \\\\\n",
    "&\\vdots\\\\\n",
    "C_{K-1}(X) &= I(c_{K-1} \\leq X < c_K) \\\\\n",
    "C_{K}(X) &= I(X \\geq c_K)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b847beec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Piecewise-constant Regression\n",
    "\n",
    "- Example use: when age is defined in 5-years bins.\n",
    "\n",
    "- Detail: $C_0(x_i) + C_1(x_i) + \\cdots + C_K(x_i) = 1$. This would make adding all pieces impossible:\n",
    "    + Perfect Collinearity.\n",
    "\n",
    "- The regression model becomes:\n",
    "\n",
    "$$ y_i = \\beta_0 + \\beta_1C_1(x_i) + \\beta_2C_2(x_i) +\\cdots + \\beta_KC_K(x_i) + \\varepsilon_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd797fb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Piecewise-constant Regression\n",
    "\n",
    "![img](https://github.com/umbertomig/POLI175public/blob/main/img/pcreg1.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445b0714",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Piecewise-constant Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5590cd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Piecewise-constant Regression\n",
    "X = educ.reset_index()['income'].to_frame()\n",
    "X = pd.cut(X.income, bins = [0, 2500, 3000, 3200, 3500, 4000, 5000])\n",
    "X = pd.get_dummies(X, drop_first = True)\n",
    "reg = LinearRegression().fit(X, y)\n",
    "print('The MSE for this piecewise constant regression is: ' + str(np.mean((reg.predict(X) - y) ** 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c877009e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e30f8c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## With cross-validation now\n",
    "X = educ.reset_index()['income'].to_frame()\n",
    "X = pd.cut(X.income, bins = [0, 2500, 3000, 3200, 3500, 4000, 5000])\n",
    "X = pd.get_dummies(X, drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 12345)\n",
    "X_train = poly.fit_transform(X_train)\n",
    "X_test = poly.fit_transform(X_test)\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "print('The CV-MSE for this piecewise constant regression is: ' + str(np.mean((reg.predict(X_test) - y_test) ** 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1280d845",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16edb64c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# See you in the next class!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
